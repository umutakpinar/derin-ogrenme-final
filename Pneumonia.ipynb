{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyVN8jfc_L1d"
      },
      "source": [
        "### Drivemızı ekliyoruz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFOeQjwSHeV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f982ea22-efa8-46fa-c26e-2823662e7db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v426lD42_YGX"
      },
      "source": [
        "### Dosyamızı da ekleyip alt klasötlerimizi ayırıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob"
      ],
      "metadata": {
        "id": "41kGEcC0iQRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wbv8-cGndd--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee28557-99e6-41ba-cb37-7534fc4296dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Viral', 'Bacterial']\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "print(os.listdir(\"/content/drive/MyDrive/DerinOgrenme/Pneumonia/X-Ray/\"))\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/DerinOgrenme/Pneumonia/X-Ray/'\n",
        "\n",
        "img_height, img_width = 128, 128\n",
        "data_path = \"/content/drive/MyDrive/DerinOgrenme/Pneumonia/X-Ray\"\n",
        "viral_path = os.path.join(data_path, \"Viral\")\n",
        "bacterial_path = os.path.join(data_path, \"Bacterial\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKjBYFTb_m3E"
      },
      "source": [
        "### Görüntüyü okuyup boyutlandırıyoruz. Veri setini birleştirip, test ve eğitim olarak ayırıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf-gV5Uy5KW-"
      },
      "outputs": [],
      "source": [
        "def load_images(folder_path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Error: Unable to read image {img_path}\")\n",
        "            continue\n",
        "        img = cv2.resize(img, (img_height, img_width))\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "viral_images, viral_labels = load_images(viral_path, 0)\n",
        "bacterial_images, bacterial_labels = load_images(bacterial_path, 1)\n",
        "\n",
        "\n",
        "x = np.concatenate((viral_images, bacterial_images), axis=0)\n",
        "y = np.concatenate((viral_labels, bacterial_labels), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state =42)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
      ],
      "metadata": {
        "id": "a-xz_MkFc3HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#----------------------------%20 CNN----------------------------\n"
      ],
      "metadata": {
        "id": "g7n4uNRHCPjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "id": "xxxMd47QCij8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_yCl = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "test_yCl = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "valid_yCl = tf.keras.utils.to_categorical(y_val, num_classes=2)"
      ],
      "metadata": {
        "id": "qtilIV8kCkro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4ZM_gKQk5qw",
        "outputId": "eb414b9d-ef28-42ee-8685-7d891fa224ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "    model.add(Conv2D(filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=16),\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     input_shape=(img_height, img_width, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    model.add(Conv2D(filters=hp.Int('conv2_filters', min_value=64, max_value=256, step=16),\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Flatten Layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Dense Layer 1\n",
        "    model.add(Dense(units=hp.Int('dense1_units', min_value=256, max_value=1024, step=64)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(rate=hp.Float('dropout1', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Dense Layer 2\n",
        "    model.add(Dense(units=hp.Int('dense2_units', min_value=128, max_value=512, step=64)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(rate=hp.Float('dropout2', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Modeli derleyin\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "sy1wo_CxCmCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16ac75c-8381-430a-99aa-6d1b1675a9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-3c2453c56ba3>:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras Tuner'ın RandomSearch sınıfını kullanarak tuner'ı oluşturun\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # Denenecek maksimum model sayısı\n",
        "    directory='my_dir',  # Kaydedilen modellerin ve sonuçların saklandığı dizin\n",
        "    project_name='pneumonia_hyperparameter_tuning'  # Tuning projesinin adı\n",
        ")\n",
        "\n",
        "# Tuner'ı eğitim verisi ile uydurun\n",
        "tuner.search(x_train, train_yCl, epochs=10, validation_data=(x_val, valid_yCl))\n",
        "\n",
        "# En iyi hiperparametreleri ve modeli alın\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Eğitim seti üzerinde en iyi modeli eğitin\n",
        "best_model.fit(x_train, train_yCl, epochs=10, validation_data=(x_val, valid_yCl))"
      ],
      "metadata": {
        "id": "0yJzphelCtVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c0fb38-8426-4d4c-a58e-ea49ae9042d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 03m 09s]\n",
            "val_accuracy: 0.943511426448822\n",
            "\n",
            "Best val_accuracy So Far: 0.9694656729698181\n",
            "Total elapsed time: 00h 29m 59s\n",
            "Epoch 1/10\n",
            "369/369 [==============================] - 10s 22ms/step - loss: 6.5678 - accuracy: 0.7335 - val_loss: 0.4469 - val_accuracy: 0.8008\n",
            "Epoch 2/10\n",
            "369/369 [==============================] - 8s 22ms/step - loss: 0.3725 - accuracy: 0.8404 - val_loss: 0.2798 - val_accuracy: 0.8771\n",
            "Epoch 3/10\n",
            "369/369 [==============================] - 8s 21ms/step - loss: 0.2415 - accuracy: 0.9040 - val_loss: 0.2012 - val_accuracy: 0.9336\n",
            "Epoch 4/10\n",
            "369/369 [==============================] - 8s 22ms/step - loss: 0.1691 - accuracy: 0.9360 - val_loss: 0.1640 - val_accuracy: 0.9427\n",
            "Epoch 5/10\n",
            "369/369 [==============================] - 8s 21ms/step - loss: 0.1282 - accuracy: 0.9530 - val_loss: 0.1905 - val_accuracy: 0.9420\n",
            "Epoch 6/10\n",
            "369/369 [==============================] - 8s 22ms/step - loss: 0.0890 - accuracy: 0.9680 - val_loss: 0.0865 - val_accuracy: 0.9710\n",
            "Epoch 7/10\n",
            "369/369 [==============================] - 8s 22ms/step - loss: 0.0888 - accuracy: 0.9710 - val_loss: 0.1609 - val_accuracy: 0.9565\n",
            "Epoch 8/10\n",
            "369/369 [==============================] - 8s 22ms/step - loss: 0.0867 - accuracy: 0.9714 - val_loss: 0.1065 - val_accuracy: 0.9748\n",
            "Epoch 9/10\n",
            "369/369 [==============================] - 8s 22ms/step - loss: 0.0626 - accuracy: 0.9813 - val_loss: 0.1073 - val_accuracy: 0.9641\n",
            "Epoch 10/10\n",
            "369/369 [==============================] - 8s 22ms/step - loss: 0.0604 - accuracy: 0.9806 - val_loss: 0.0796 - val_accuracy: 0.9733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x783e73ff6b30>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_valid = best_model.evaluate(x_val, valid_yCl)\n",
        "print(\"Validation Accuracy: \", score_valid[1])\n",
        "\n",
        "score_test = best_model.evaluate(x_test, test_yCl)\n",
        "print(\"Test Accuracy: \", score_test[1])\n",
        "\n",
        "score_train = best_model.evaluate(x_train, train_yCl)\n",
        "print(\"Training Accuracy: \", score_train[1])"
      ],
      "metadata": {
        "id": "SIyD5Pw8CpaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537d847c-826d-42e2-abe9-975a78ee83b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 8ms/step - loss: 0.0796 - accuracy: 0.9733\n",
            "Validation Accuracy:  0.9732824563980103\n",
            "103/103 [==============================] - 1s 12ms/step - loss: 0.2164 - accuracy: 0.9585\n",
            "Test Accuracy:  0.958473265171051\n",
            "369/369 [==============================] - 2s 6ms/step - loss: 0.0353 - accuracy: 0.9878\n",
            "Training Accuracy:  0.9877852201461792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test verisi üzerinde tahminlerin yapılması\n",
        "y_pred = best_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(test_yCl, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred_classes, labels=np.unique(y_true))\n",
        "print('Classification Report:')\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oQv8tCiMhGV",
        "outputId": "617425bc-3c4d-4c04-8a14-273b07aa1733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103/103 [==============================] - 1s 6ms/step\n",
            "Test Accuracy: 0.9585\n",
            "Precision: 0.9589\n",
            "Recall: 0.9585\n",
            "F1 Score: 0.9586\n",
            "Confusion Matrix:\n",
            "[[1191   52]\n",
            " [  84 1948]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.95      1243\n",
            "           1       0.97      0.96      0.97      2032\n",
            "\n",
            "    accuracy                           0.96      3275\n",
            "   macro avg       0.95      0.96      0.96      3275\n",
            "weighted avg       0.96      0.96      0.96      3275\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#----------------------------%20 YSA----------------------------\n"
      ],
      "metadata": {
        "id": "BZbw6iEUSMb7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi1xdRh6AW4C"
      },
      "source": [
        "### Bir yapay sinir ağı oluşturuyoruz. 3 katman içeriyor. Giriş katmanı, Çıkış katmanı ve 2 gizli katman içermekte. İlk gizli katman 128 ikinci gizli katman 64 sinir ağı içermekte. Bazı metrikleri kullanarak modelimizi derliyoruz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwRntmC66Rft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02cfcf0-f8f4-4743-ab6f-4f6b954b327e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "332/332 [==============================] - 4s 6ms/step - loss: 270.3531 - accuracy: 0.6274 - val_loss: 55.4873 - val_accuracy: 0.6556\n",
            "Epoch 2/10\n",
            "332/332 [==============================] - 2s 5ms/step - loss: 59.6184 - accuracy: 0.6532 - val_loss: 33.2392 - val_accuracy: 0.6768\n",
            "Epoch 3/10\n",
            "332/332 [==============================] - 2s 6ms/step - loss: 13.8717 - accuracy: 0.6687 - val_loss: 1.9813 - val_accuracy: 0.7354\n",
            "Epoch 4/10\n",
            "332/332 [==============================] - 2s 7ms/step - loss: 5.2549 - accuracy: 0.6453 - val_loss: 2.0600 - val_accuracy: 0.6429\n",
            "Epoch 5/10\n",
            "332/332 [==============================] - 2s 6ms/step - loss: 1.0735 - accuracy: 0.7106 - val_loss: 0.8464 - val_accuracy: 0.6735\n",
            "Epoch 6/10\n",
            "332/332 [==============================] - 2s 5ms/step - loss: 0.6679 - accuracy: 0.7218 - val_loss: 0.8428 - val_accuracy: 0.6421\n",
            "Epoch 7/10\n",
            "332/332 [==============================] - 2s 5ms/step - loss: 9.3919 - accuracy: 0.5963 - val_loss: 0.6804 - val_accuracy: 0.6175\n",
            "Epoch 8/10\n",
            "332/332 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.6190 - val_loss: 0.6671 - val_accuracy: 0.6175\n",
            "Epoch 9/10\n",
            "332/332 [==============================] - 2s 5ms/step - loss: 0.6654 - accuracy: 0.6190 - val_loss: 0.6654 - val_accuracy: 0.6175\n",
            "Epoch 10/10\n",
            "332/332 [==============================] - 2s 5ms/step - loss: 0.6646 - accuracy: 0.6190 - val_loss: 0.6653 - val_accuracy: 0.6175\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x783e73dffe20>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(img_height, img_width, 3)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98wvuifcBR59"
      },
      "source": [
        "### En son test verisi üzerinde modelimizi kullanıyoruz ve değerlendirmemizi alıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuM_jOyr7J9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40684a5e-01de-4c6a-c1c7-628b12c8438e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103/103 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.6204580152671756\n",
            "Precision: 0.6204580152671756\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7657810439042774\n",
            "Confusion Matrix:\n",
            "[[   0 1243]\n",
            " [   0 2032]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1243\n",
            "           1       0.62      1.00      0.77      2032\n",
            "\n",
            "    accuracy                           0.62      3275\n",
            "   macro avg       0.31      0.50      0.38      3275\n",
            "weighted avg       0.38      0.62      0.48      3275\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)\n",
        "y_pred = (predictions > 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#----------------------------%20 TL----------------------------"
      ],
      "metadata": {
        "id": "hyRiSci0P-vA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet121"
      ],
      "metadata": {
        "id": "L8skuccLQMh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
        "\n",
        "#Input layerımızı belirleyelim inputlarımızı densenet121 preprocess'ine uyduralım\n",
        "input_layer = tf.keras.Input((img_width,img_height,3))\n",
        "preprocessed_inputs = tf.keras.layers.Lambda( lambda x : preprocess_input(x))(input_layer)\n",
        "\n",
        "#DenseNet121 için base model oluşturalım.\n",
        "base_model = DenseNet121(\n",
        "    weights = \"imagenet\",\n",
        "    include_top = False, # Yalnızca Conv blocks kısmını include etsin.\n",
        "    input_tensor = preprocessed_inputs # modele gelecek preprocessed inputlar\n",
        ")\n",
        "\n",
        "#Model outputuna Pooling ve Dense ekleyelim\n",
        "k = GlobalAveragePooling2D()(base_model.output)\n",
        "k = Dense(2)(k)\n",
        "\n",
        "# Transfer modelimizin input ve output layerlarının set edilmesi\n",
        "transfer_learning_model = tf.keras.Model(inputs = input_layer, outputs = k)\n",
        "\n",
        "from tensorflow import keras\n",
        "# Şimdi early stopping callbacklarimizi oluşturalım.\n",
        "callback_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model.h5',\n",
        "        monitor = 'val_accuracy', save_best_only=True, verbose=3\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=3)\n",
        "]\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor = \"val_loss\",\n",
        "    factor = 0.1,\n",
        "    patience = 3,\n",
        "    mode = \"min\",\n",
        "    verbose = 1,\n",
        "    min_lr = 1e-8\n",
        ")\n",
        "\n",
        "callback_list.append(reduce_lr)\n",
        "\n",
        "#Modelimizi compile edelim\n",
        "transfer_learning_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "#Modelimizi eğitiyoruz.\n",
        "transfer_learning_model.fit(\n",
        "            x_train,\n",
        "            train_yCl,\n",
        "            epochs = 10,\n",
        "            batch_size = 64,\n",
        "            validation_data = (x_val, valid_yCl),\n",
        "            callbacks = callback_list\n",
        "            )"
      ],
      "metadata": {
        "id": "LxqBzmoAQQZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0537132f-fe95-41d4-9672-a1bd5a7f33ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.5575 - accuracy: 0.6410\n",
            "Epoch 1: val_accuracy improved from -inf to 0.37328, saving model to model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r185/185 [==============================] - 128s 285ms/step - loss: 5.5575 - accuracy: 0.6410 - val_loss: 9.6105 - val_accuracy: 0.3733 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.3956 - accuracy: 0.6375\n",
            "Epoch 2: val_accuracy improved from 0.37328 to 0.63053, saving model to model.h5\n",
            "185/185 [==============================] - 43s 234ms/step - loss: 5.3956 - accuracy: 0.6375 - val_loss: 5.6665 - val_accuracy: 0.6305 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 6.7610 - accuracy: 0.5386\n",
            "Epoch 3: val_accuracy did not improve from 0.63053\n",
            "185/185 [==============================] - 42s 228ms/step - loss: 6.7610 - accuracy: 0.5386 - val_loss: 5.9864 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.8682 - accuracy: 0.5962\n",
            "Epoch 4: val_accuracy did not improve from 0.63053\n",
            "185/185 [==============================] - 42s 229ms/step - loss: 5.8682 - accuracy: 0.5962 - val_loss: 9.6706 - val_accuracy: 0.3695 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.8387 - accuracy: 0.6136\n",
            "Epoch 5: val_accuracy did not improve from 0.63053\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "185/185 [==============================] - 45s 244ms/step - loss: 5.8387 - accuracy: 0.6136 - val_loss: 5.7039 - val_accuracy: 0.6267 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.5182 - accuracy: 0.6322\n",
            "Epoch 6: val_accuracy improved from 0.63053 to 0.65573, saving model to model.h5\n",
            "185/185 [==============================] - 44s 239ms/step - loss: 5.5182 - accuracy: 0.6322 - val_loss: 5.0930 - val_accuracy: 0.6557 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.0743 - accuracy: 0.6562\n",
            "Epoch 7: val_accuracy improved from 0.65573 to 0.66260, saving model to model.h5\n",
            "185/185 [==============================] - 45s 242ms/step - loss: 5.0743 - accuracy: 0.6562 - val_loss: 5.0847 - val_accuracy: 0.6626 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.2568 - accuracy: 0.6491\n",
            "Epoch 8: val_accuracy did not improve from 0.66260\n",
            "185/185 [==============================] - 42s 229ms/step - loss: 5.2568 - accuracy: 0.6491 - val_loss: 5.3550 - val_accuracy: 0.6435 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.1618 - accuracy: 0.6576\n",
            "Epoch 9: val_accuracy improved from 0.66260 to 0.67557, saving model to model.h5\n",
            "185/185 [==============================] - 44s 240ms/step - loss: 5.1618 - accuracy: 0.6576 - val_loss: 4.8795 - val_accuracy: 0.6756 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 5.0777 - accuracy: 0.6625\n",
            "Epoch 10: val_accuracy did not improve from 0.67557\n",
            "185/185 [==============================] - 43s 232ms/step - loss: 5.0777 - accuracy: 0.6625 - val_loss: 4.9998 - val_accuracy: 0.6702 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78ba085958d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test verisi üzerinde DenseNet121 modelimizi değerlendirelim"
      ],
      "metadata": {
        "id": "lxsjHF9VRDAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelimizin Validation, Test ve Train Acurracy Skorlarını hesaplayalım.\n",
        "score_valid = transfer_learning_model.evaluate(x_val, valid_yCl)\n",
        "print(\"Validation Accuracy: \", score_valid[1])\n",
        "\n",
        "score_test = transfer_learning_model.evaluate(x_test, test_yCl)\n",
        "print(\"Validation Accuracy: \", score_test[1])\n",
        "\n",
        "score_train = transfer_learning_model.evaluate(x_train, train_yCl)\n",
        "print(\"Validation Accuracy: \", score_train[1])\n",
        "\n",
        "# Test verisi üzerinde tahminlerin yapılması\n",
        "y_pred = transfer_learning_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(test_yCl, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred_classes, labels=np.unique(y_true))\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "K5aN7gHZRMXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04c3866-81ec-49d2-95eb-e348ac46af78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 4s 33ms/step - loss: 4.9998 - accuracy: 0.6702\n",
            "Validation Accuracy:  0.6702290177345276\n",
            "103/103 [==============================] - 5s 53ms/step - loss: 5.2265 - accuracy: 0.6547\n",
            "Validation Accuracy:  0.6546564698219299\n",
            "369/369 [==============================] - 12s 33ms/step - loss: 5.1408 - accuracy: 0.6593\n",
            "Validation Accuracy:  0.6592586040496826\n",
            "103/103 [==============================] - 5s 31ms/step\n",
            "Test Accuracy: 0.6547\n",
            "Precision: 0.6396\n",
            "Recall: 0.6547\n",
            "F1 Score: 0.6345\n",
            "Confusion Matrix:\n",
            "[[ 458  785]\n",
            " [ 346 1686]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.37      0.45      1243\n",
            "           1       0.68      0.83      0.75      2032\n",
            "\n",
            "    accuracy                           0.65      3275\n",
            "   macro avg       0.63      0.60      0.60      3275\n",
            "weighted avg       0.64      0.65      0.63      3275\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNetB0"
      ],
      "metadata": {
        "id": "fg68aSMERkQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "# DenseNet121'de olduğu şekilde EfficientNetB0 modelimizi oluşturuyoruz.\n",
        "base_model = EfficientNetB0(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(img_width, img_height, 3)\n",
        ")\n",
        "\n",
        "k = GlobalMaxPooling2D()(base_model.output)\n",
        "k = Dense(2)(k)\n",
        "\n",
        "transfer_learning_model_efficientnet = tf.keras.Model(inputs=base_model.input, outputs=k)\n",
        "\n",
        "transfer_learning_model_efficientnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callback_list_efficientnet = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model_efficientnet.h5',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=3\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=3)\n",
        "]\n",
        "\n",
        "transfer_learning_model_efficientnet.fit(\n",
        "    x_train,\n",
        "    train_yCl,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_val, valid_yCl),\n",
        "    callbacks=callback_list_efficientnet\n",
        ")"
      ],
      "metadata": {
        "id": "bTXoe22kRr-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d70a6c-7626-44fe-d7e9-c9361caf384a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 1.0301 - accuracy: 0.6419\n",
            "Epoch 1: val_accuracy improved from -inf to 0.58397, saving model to model_efficientnet.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r185/185 [==============================] - 76s 202ms/step - loss: 1.0301 - accuracy: 0.6419 - val_loss: 0.6807 - val_accuracy: 0.5840\n",
            "Epoch 2/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.6060 - accuracy: 0.7001\n",
            "Epoch 2: val_accuracy improved from 0.58397 to 0.71221, saving model to model_efficientnet.h5\n",
            "185/185 [==============================] - 33s 180ms/step - loss: 0.6060 - accuracy: 0.7001 - val_loss: 0.5592 - val_accuracy: 0.7122\n",
            "Epoch 3/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.7705\n",
            "Epoch 3: val_accuracy improved from 0.71221 to 0.78626, saving model to model_efficientnet.h5\n",
            "185/185 [==============================] - 33s 179ms/step - loss: 0.5146 - accuracy: 0.7705 - val_loss: 0.4756 - val_accuracy: 0.7863\n",
            "Epoch 4/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7590\n",
            "Epoch 4: val_accuracy did not improve from 0.78626\n",
            "185/185 [==============================] - 32s 174ms/step - loss: 0.5041 - accuracy: 0.7590 - val_loss: 0.5984 - val_accuracy: 0.7206\n",
            "Epoch 5/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.6009 - accuracy: 0.6793\n",
            "Epoch 5: val_accuracy did not improve from 0.78626\n",
            "185/185 [==============================] - 33s 177ms/step - loss: 0.6009 - accuracy: 0.6793 - val_loss: 0.7087 - val_accuracy: 0.4519\n",
            "Epoch 6/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.7650\n",
            "Epoch 6: val_accuracy did not improve from 0.78626\n",
            "185/185 [==============================] - 32s 173ms/step - loss: 0.5003 - accuracy: 0.7650 - val_loss: 0.5042 - val_accuracy: 0.7756\n",
            "Epoch 7/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.8122\n",
            "Epoch 7: val_accuracy improved from 0.78626 to 0.79389, saving model to model_efficientnet.h5\n",
            "185/185 [==============================] - 33s 177ms/step - loss: 0.4361 - accuracy: 0.8122 - val_loss: 0.4484 - val_accuracy: 0.7939\n",
            "Epoch 8/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.5545 - accuracy: 0.7329\n",
            "Epoch 8: val_accuracy did not improve from 0.79389\n",
            "185/185 [==============================] - 33s 176ms/step - loss: 0.5545 - accuracy: 0.7329 - val_loss: 0.6548 - val_accuracy: 0.5687\n",
            "Epoch 9/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.7657\n",
            "Epoch 9: val_accuracy did not improve from 0.79389\n",
            "185/185 [==============================] - 32s 174ms/step - loss: 0.5034 - accuracy: 0.7657 - val_loss: 0.4805 - val_accuracy: 0.7908\n",
            "Epoch 10/10\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.8096\n",
            "Epoch 10: val_accuracy improved from 0.79389 to 0.80000, saving model to model_efficientnet.h5\n",
            "185/185 [==============================] - 33s 178ms/step - loss: 0.4313 - accuracy: 0.8096 - val_loss: 0.4570 - val_accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x783e200b0a30>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test verisi üzerinde EfficientNetB0 modelimizi değerlendirelim"
      ],
      "metadata": {
        "id": "ozDQclUgR0iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_valid = transfer_learning_model.evaluate(x_val, valid_yCl)\n",
        "print(\"Validation Accuracy: \", score_valid[1])\n",
        "\n",
        "score_test = transfer_learning_model.evaluate(x_test, test_yCl)\n",
        "print(\"Validation Accuracy: \", score_test[1])\n",
        "\n",
        "score_train = transfer_learning_model.evaluate(x_train, train_yCl)\n",
        "print(\"Validation Accuracy: \", score_train[1])\n",
        "\n",
        "# Test verisi üzerinde tahminlerin yapılması\n",
        "y_pred = transfer_learning_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(test_yCl, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred_classes, labels=np.unique(y_true))\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "l2HVpQlmR7zP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c415441-2184-4283-f1c3-f12af8c97197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 2s 38ms/step - loss: 5.4128 - accuracy: 0.6626\n",
            "Validation Accuracy:  0.6625953912734985\n",
            "103/103 [==============================] - 3s 33ms/step - loss: 5.3909 - accuracy: 0.6660\n",
            "Validation Accuracy:  0.6659541726112366\n",
            "369/369 [==============================] - 13s 34ms/step - loss: 5.2749 - accuracy: 0.6754\n",
            "Validation Accuracy:  0.6753753423690796\n",
            "103/103 [==============================] - 3s 33ms/step\n",
            "Test Accuracy: 0.6660\n",
            "Precision: 0.6529\n",
            "Recall: 0.6660\n",
            "F1 Score: 0.6432\n",
            "Confusion Matrix:\n",
            "[[ 453  790]\n",
            " [ 304 1728]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.36      0.45      1243\n",
            "           1       0.69      0.85      0.76      2032\n",
            "\n",
            "    accuracy                           0.67      3275\n",
            "   macro avg       0.64      0.61      0.61      3275\n",
            "weighted avg       0.65      0.67      0.64      3275\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#%35 ayırma"
      ],
      "metadata": {
        "id": "2Ssm_sB2eaMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Veri setini ayırma\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state =42)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
      ],
      "metadata": {
        "id": "u231ZV4-eehE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#----------------------------%35 CNN----------------------------\n"
      ],
      "metadata": {
        "id": "-WNxdLPNemhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "id": "U3-qtlAKemhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_yCl = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "test_yCl = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "valid_yCl = tf.keras.utils.to_categorical(y_val, num_classes=2)"
      ],
      "metadata": {
        "id": "tVEJePEmemha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "    model.add(Conv2D(filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=16),\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     input_shape=(img_height, img_width, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    model.add(Conv2D(filters=hp.Int('conv2_filters', min_value=64, max_value=256, step=16),\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Flatten Layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Dense Layer 1\n",
        "    model.add(Dense(units=hp.Int('dense1_units', min_value=256, max_value=1024, step=64)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(rate=hp.Float('dropout1', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Dense Layer 2\n",
        "    model.add(Dense(units=hp.Int('dense2_units', min_value=128, max_value=512, step=64)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(rate=hp.Float('dropout2', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Modeli derleyin\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "YO2g5GC4emha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b1c965-f7a8-41bf-c864-5ecd6f28b6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-3c2453c56ba3>:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras Tuner'ın RandomSearch sınıfını kullanarak tuner'ı oluşturun\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # Denenecek maksimum model sayısı\n",
        "    directory='my_dir',  # Kaydedilen modellerin ve sonuçların saklandığı dizin\n",
        "    project_name='pneumonia_hyperparameter_tuning'  # Tuning projesinin adı\n",
        ")\n",
        "\n",
        "# Tuner'ı eğitim verisi ile uydurun\n",
        "tuner.search(x_train, train_yCl, epochs=10, validation_data=(x_val, valid_yCl))\n",
        "\n",
        "# En iyi hiperparametreleri ve modeli alın\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Eğitim seti üzerinde en iyi modeli eğitin\n",
        "best_model.fit(x_train, train_yCl, epochs=10, validation_data=(x_val, valid_yCl))"
      ],
      "metadata": {
        "id": "HC7AwTdSemha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17de8d5-46f2-4242-c714-e5800a95a443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from my_dir/pneumonia_hyperparameter_tuning/tuner0.json\n",
            "Epoch 1/10\n",
            "300/300 [==============================] - 13s 24ms/step - loss: 11.1968 - accuracy: 0.7366 - val_loss: 0.4471 - val_accuracy: 0.7878\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 6s 21ms/step - loss: 0.3675 - accuracy: 0.8426 - val_loss: 0.3388 - val_accuracy: 0.8563\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 7s 22ms/step - loss: 0.2388 - accuracy: 0.9037 - val_loss: 0.3452 - val_accuracy: 0.8854\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.1846 - accuracy: 0.9276 - val_loss: 0.2819 - val_accuracy: 0.9052\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 6s 22ms/step - loss: 0.1497 - accuracy: 0.9451 - val_loss: 0.3936 - val_accuracy: 0.8761\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 6s 21ms/step - loss: 0.1299 - accuracy: 0.9510 - val_loss: 0.2880 - val_accuracy: 0.9474\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 6s 21ms/step - loss: 0.1074 - accuracy: 0.9629 - val_loss: 0.3330 - val_accuracy: 0.9305\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 6s 21ms/step - loss: 0.0817 - accuracy: 0.9710 - val_loss: 0.3603 - val_accuracy: 0.9239\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 6s 21ms/step - loss: 0.0829 - accuracy: 0.9730 - val_loss: 0.3578 - val_accuracy: 0.9202\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 7s 22ms/step - loss: 0.0606 - accuracy: 0.9811 - val_loss: 0.3418 - val_accuracy: 0.9502\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7964174e02e0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_valid = best_model.evaluate(x_val, valid_yCl)\n",
        "print(\"Validation Accuracy: \", score_valid[1])\n",
        "\n",
        "score_test = best_model.evaluate(x_test, test_yCl)\n",
        "print(\"Test Accuracy: \", score_test[1])\n",
        "\n",
        "score_train = best_model.evaluate(x_train, train_yCl)\n",
        "print(\"Training Accuracy: \", score_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mvi8_QLemha",
        "outputId": "18e5662d-e83c-4417-9bb5-5282a1743efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3418 - accuracy: 0.9502\n",
            "Validation Accuracy:  0.9502347707748413\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 0.3064 - accuracy: 0.9510\n",
            "Test Accuracy:  0.9509684443473816\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0183 - accuracy: 0.9928\n",
            "Training Accuracy:  0.992796003818512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test verisi üzerinde tahminlerin yapılması\n",
        "y_pred = best_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(test_yCl, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred_classes, labels=np.unique(y_true))\n",
        "print('Classification Report:')\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3uDdVwLemhq",
        "outputId": "35af4bf4-bc13-4c7c-bac3-a6f24a9161fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 6ms/step\n",
            "Test Accuracy: 0.9510\n",
            "Precision: 0.9511\n",
            "Recall: 0.9510\n",
            "F1 Score: 0.9508\n",
            "Confusion Matrix:\n",
            "[[2018  185]\n",
            " [  96 3432]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93      2203\n",
            "           1       0.95      0.97      0.96      3528\n",
            "\n",
            "    accuracy                           0.95      5731\n",
            "   macro avg       0.95      0.94      0.95      5731\n",
            "weighted avg       0.95      0.95      0.95      5731\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3asxskTBe1O"
      },
      "source": [
        "#----------------------------%35 YSA----------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10WnJ0PQ7xmF",
        "outputId": "2f3d995a-0f69-48cb-cb95-877ae825c122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "270/270 [==============================] - 6s 8ms/step - loss: 172.3777 - accuracy: 0.6255 - val_loss: 755.4120 - val_accuracy: 0.6054\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 73.9758 - accuracy: 0.6435 - val_loss: 61.4942 - val_accuracy: 0.6253\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 24.8265 - accuracy: 0.6802 - val_loss: 7.5354 - val_accuracy: 0.7672\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 2s 6ms/step - loss: 12.5693 - accuracy: 0.6933 - val_loss: 17.1789 - val_accuracy: 0.5303\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 5.8026 - accuracy: 0.7124 - val_loss: 4.0001 - val_accuracy: 0.7015\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 1.8509 - accuracy: 0.7346 - val_loss: 1.8562 - val_accuracy: 0.6754\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 12.7299 - accuracy: 0.6669 - val_loss: 6.1685 - val_accuracy: 0.7161\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 6.2271 - accuracy: 0.6780 - val_loss: 0.6880 - val_accuracy: 0.7620\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 0.7631 - accuracy: 0.7326 - val_loss: 0.5604 - val_accuracy: 0.7599\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 1s 5ms/step - loss: 2.2335 - accuracy: 0.6990 - val_loss: 5.8804 - val_accuracy: 0.5501\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79641432df30>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(img_height, img_width, 3)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W6Ri45Y84-u",
        "outputId": "31958b16-4f87-41d9-f987-07fe30a07b22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.5328912929680684\n",
            "Precision: 0.9167482859941234\n",
            "Recall: 0.2653061224489796\n",
            "F1 Score: 0.41151901516816886\n",
            "Confusion Matrix:\n",
            "[[2118   85]\n",
            " [2592  936]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.96      0.61      2203\n",
            "           1       0.92      0.27      0.41      3528\n",
            "\n",
            "    accuracy                           0.53      5731\n",
            "   macro avg       0.68      0.61      0.51      5731\n",
            "weighted avg       0.74      0.53      0.49      5731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)\n",
        "y_pred = (predictions > 0.5).astype(int)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#----------------------------%35 TL----------------------------"
      ],
      "metadata": {
        "id": "uDb9USGKSGtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet121"
      ],
      "metadata": {
        "id": "1vOcnQUTSgnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
        "\n",
        "input_layer = tf.keras.Input((img_width,img_height,3))\n",
        "preprocessed_inputs = tf.keras.layers.Lambda( lambda x : preprocess_input(x))(input_layer)\n",
        "\n",
        "base_model = DenseNet121(\n",
        "    weights = \"imagenet\",\n",
        "    include_top = False,\n",
        "    input_tensor = preprocessed_inputs\n",
        ")\n",
        "\n",
        "k = GlobalAveragePooling2D()(base_model.output)\n",
        "k = Dense(2)(k)\n",
        "\n",
        "transfer_learning_model = tf.keras.Model(inputs = input_layer, outputs = k)\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "callback_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model.h5',\n",
        "        monitor = 'val_accuracy', save_best_only=True, verbose=3\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=3)\n",
        "]\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor = \"val_loss\",\n",
        "    factor = 0.1,\n",
        "    patience = 3,\n",
        "    mode = \"min\",\n",
        "    verbose = 1,\n",
        "    min_lr = 1e-8\n",
        ")\n",
        "\n",
        "callback_list.append(reduce_lr)\n",
        "\n",
        "transfer_learning_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "#Modelimizi eğitiyoruz.\n",
        "transfer_learning_model.fit(\n",
        "            x_train,\n",
        "            train_yCl,\n",
        "            epochs = 10,\n",
        "            batch_size = 64,\n",
        "            validation_data = (x_val, valid_yCl),\n",
        "            callbacks = callback_list\n",
        "            )"
      ],
      "metadata": {
        "id": "hutcLLQhSgnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d5b06d-3526-4c11-ab29-aa66966ea631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 4.8711 - accuracy: 0.6746\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46197, saving model to model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r150/150 [==============================] - 129s 346ms/step - loss: 4.8711 - accuracy: 0.6746 - val_loss: 7.8859 - val_accuracy: 0.4620 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.9923 - accuracy: 0.5958\n",
            "Epoch 2: val_accuracy did not improve from 0.46197\n",
            "150/150 [==============================] - 35s 231ms/step - loss: 5.9923 - accuracy: 0.5958 - val_loss: 9.1365 - val_accuracy: 0.3878 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.3065 - accuracy: 0.6737\n",
            "Epoch 3: val_accuracy improved from 0.46197 to 0.65164, saving model to model.h5\n",
            "150/150 [==============================] - 36s 242ms/step - loss: 5.3065 - accuracy: 0.6737 - val_loss: 5.8291 - val_accuracy: 0.6516 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.7312 - accuracy: 0.6270\n",
            "Epoch 4: val_accuracy did not improve from 0.65164\n",
            "150/150 [==============================] - 35s 233ms/step - loss: 5.7312 - accuracy: 0.6270 - val_loss: 6.2414 - val_accuracy: 0.6028 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.3284 - accuracy: 0.6679\n",
            "Epoch 5: val_accuracy did not improve from 0.65164\n",
            "150/150 [==============================] - 34s 229ms/step - loss: 5.3284 - accuracy: 0.6679 - val_loss: 5.7087 - val_accuracy: 0.6235 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.5777 - accuracy: 0.6309\n",
            "Epoch 6: val_accuracy did not improve from 0.65164\n",
            "150/150 [==============================] - 35s 236ms/step - loss: 5.5777 - accuracy: 0.6309 - val_loss: 5.5497 - val_accuracy: 0.6385 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.2691 - accuracy: 0.6664\n",
            "Epoch 7: val_accuracy improved from 0.65164 to 0.66667, saving model to model.h5\n",
            "150/150 [==============================] - 36s 243ms/step - loss: 5.2691 - accuracy: 0.6664 - val_loss: 5.4092 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.6622 - accuracy: 0.6326\n",
            "Epoch 8: val_accuracy did not improve from 0.66667\n",
            "150/150 [==============================] - 35s 231ms/step - loss: 5.6622 - accuracy: 0.6326 - val_loss: 5.9476 - val_accuracy: 0.6122 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.7710 - accuracy: 0.6237\n",
            "Epoch 9: val_accuracy did not improve from 0.66667\n",
            "150/150 [==============================] - 34s 226ms/step - loss: 5.7710 - accuracy: 0.6237 - val_loss: 5.9476 - val_accuracy: 0.6122 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 5.7710 - accuracy: 0.6237\n",
            "Epoch 10: val_accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "150/150 [==============================] - 42s 281ms/step - loss: 5.7710 - accuracy: 0.6237 - val_loss: 5.9476 - val_accuracy: 0.6122 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7963a0121e70>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test verisi üzerinde DenseNet121 modelimizi değerlendirelim"
      ],
      "metadata": {
        "id": "Apv19YpJSgnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelimizin Validation, Test ve Train Acurracy Skorlarını hesaplayalım.\n",
        "score_valid = transfer_learning_model.evaluate(x_val, valid_yCl)\n",
        "print(\"Validation Accuracy: \", score_valid[1])\n",
        "\n",
        "score_test = transfer_learning_model.evaluate(x_test, test_yCl)\n",
        "print(\"Validation Accuracy: \", score_test[1])\n",
        "\n",
        "score_train = transfer_learning_model.evaluate(x_train, train_yCl)\n",
        "print(\"Validation Accuracy: \", score_train[1])\n",
        "\n",
        "# Test verisi üzerinde tahminlerin yapılması\n",
        "y_pred = transfer_learning_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(test_yCl, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred_classes, labels=np.unique(y_true))\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "F85jWdo5SgnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9964572c-35e3-430d-b3d2-7fc50503f6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 6s 100ms/step - loss: 5.9476 - accuracy: 0.6122\n",
            "Validation Accuracy:  0.6122065782546997\n",
            "180/180 [==============================] - 8s 45ms/step - loss: 5.8956 - accuracy: 0.6156\n",
            "Validation Accuracy:  0.6155993938446045\n",
            "300/300 [==============================] - 13s 42ms/step - loss: 5.7710 - accuracy: 0.6237\n",
            "Validation Accuracy:  0.6237210035324097\n",
            "180/180 [==============================] - 9s 32ms/step\n",
            "Test Accuracy: 0.6156\n",
            "Precision: 0.3790\n",
            "Recall: 0.6156\n",
            "F1 Score: 0.4691\n",
            "Confusion Matrix:\n",
            "[[   0 2203]\n",
            " [   0 3528]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2203\n",
            "           1       0.62      1.00      0.76      3528\n",
            "\n",
            "    accuracy                           0.62      5731\n",
            "   macro avg       0.31      0.50      0.38      5731\n",
            "weighted avg       0.38      0.62      0.47      5731\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNetB0"
      ],
      "metadata": {
        "id": "ZlwsABFTSgnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "base_model = EfficientNetB0(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(img_width, img_height, 3)\n",
        ")\n",
        "\n",
        "k = GlobalMaxPooling2D()(base_model.output)\n",
        "k = Dense(2)(k)\n",
        "\n",
        "transfer_learning_model_efficientnet = tf.keras.Model(inputs=base_model.input, outputs=k)\n",
        "\n",
        "transfer_learning_model_efficientnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callback_list_efficientnet = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model_efficientnet.h5',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=3\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=3)\n",
        "]\n",
        "\n",
        "transfer_learning_model_efficientnet.fit(\n",
        "    x_train,\n",
        "    train_yCl,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_val, valid_yCl),\n",
        "    callbacks=callback_list_efficientnet\n",
        ")"
      ],
      "metadata": {
        "id": "Y031kqWsSgnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398ae103-2dd5-4f2e-d4fb-0519e5364247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.6722\n",
            "Epoch 1: val_accuracy improved from -inf to 0.66948, saving model to model_efficientnet.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r150/150 [==============================] - 72s 226ms/step - loss: 0.7023 - accuracy: 0.6722 - val_loss: 0.5977 - val_accuracy: 0.6695\n",
            "Epoch 2/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.7507\n",
            "Epoch 2: val_accuracy improved from 0.66948 to 0.74648, saving model to model_efficientnet.h5\n",
            "150/150 [==============================] - 27s 181ms/step - loss: 0.5415 - accuracy: 0.7507 - val_loss: 0.5420 - val_accuracy: 0.7465\n",
            "Epoch 3/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.7734\n",
            "Epoch 3: val_accuracy did not improve from 0.74648\n",
            "150/150 [==============================] - 26s 175ms/step - loss: 0.5122 - accuracy: 0.7734 - val_loss: 0.5746 - val_accuracy: 0.7042\n",
            "Epoch 4/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.7752\n",
            "Epoch 4: val_accuracy did not improve from 0.74648\n",
            "150/150 [==============================] - 26s 176ms/step - loss: 0.5126 - accuracy: 0.7752 - val_loss: 0.5607 - val_accuracy: 0.7427\n",
            "Epoch 5/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.8044\n",
            "Epoch 5: val_accuracy did not improve from 0.74648\n",
            "150/150 [==============================] - 27s 178ms/step - loss: 0.4663 - accuracy: 0.8044 - val_loss: 0.5413 - val_accuracy: 0.7296\n",
            "Epoch 6/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.7061\n",
            "Epoch 6: val_accuracy did not improve from 0.74648\n",
            "150/150 [==============================] - 27s 180ms/step - loss: 0.5589 - accuracy: 0.7061 - val_loss: 0.6334 - val_accuracy: 0.6545\n",
            "Epoch 7/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.6886\n",
            "Epoch 7: val_accuracy did not improve from 0.74648\n",
            "150/150 [==============================] - 27s 180ms/step - loss: 0.5866 - accuracy: 0.6886 - val_loss: 0.6820 - val_accuracy: 0.6235\n",
            "Epoch 8/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.7505\n",
            "Epoch 8: val_accuracy did not improve from 0.74648\n",
            "150/150 [==============================] - 26s 174ms/step - loss: 0.5425 - accuracy: 0.7505 - val_loss: 0.7891 - val_accuracy: 0.6131\n",
            "Epoch 9/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.7313\n",
            "Epoch 9: val_accuracy improved from 0.74648 to 0.77277, saving model to model_efficientnet.h5\n",
            "150/150 [==============================] - 27s 180ms/step - loss: 0.5486 - accuracy: 0.7313 - val_loss: 0.5137 - val_accuracy: 0.7728\n",
            "Epoch 10/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.4752 - accuracy: 0.7791\n",
            "Epoch 10: val_accuracy improved from 0.77277 to 0.77371, saving model to model_efficientnet.h5\n",
            "150/150 [==============================] - 28s 185ms/step - loss: 0.4752 - accuracy: 0.7791 - val_loss: 0.4818 - val_accuracy: 0.7737\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7963565ffa60>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test verisi üzerinde EfficientNetB0 modelimizi değerlendirelim"
      ],
      "metadata": {
        "id": "PU2xEw8WSgnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_valid = transfer_learning_model.evaluate(x_val, valid_yCl)\n",
        "print(\"Validation Accuracy: \", score_valid[1])\n",
        "\n",
        "score_test = transfer_learning_model.evaluate(x_test, test_yCl)\n",
        "print(\"Validation Accuracy: \", score_test[1])\n",
        "\n",
        "score_train = transfer_learning_model.evaluate(x_train, train_yCl)\n",
        "print(\"Validation Accuracy: \", score_train[1])\n",
        "\n",
        "# Test verisi üzerinde tahminlerin yapılması\n",
        "y_pred = transfer_learning_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(test_yCl, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred_classes, labels=np.unique(y_true))\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "zTkKP5z7SgnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab64864-5a7a-4b2c-d06f-1880361fec71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 1s 40ms/step - loss: 5.9476 - accuracy: 0.6122\n",
            "Validation Accuracy:  0.6122065782546997\n",
            "180/180 [==============================] - 6s 34ms/step - loss: 5.8956 - accuracy: 0.6156\n",
            "Validation Accuracy:  0.6155993938446045\n",
            "300/300 [==============================] - 10s 34ms/step - loss: 5.7710 - accuracy: 0.6237\n",
            "Validation Accuracy:  0.6237210035324097\n",
            "180/180 [==============================] - 6s 31ms/step\n",
            "Test Accuracy: 0.6156\n",
            "Precision: 0.3790\n",
            "Recall: 0.6156\n",
            "F1 Score: 0.4691\n",
            "Confusion Matrix:\n",
            "[[   0 2203]\n",
            " [   0 3528]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2203\n",
            "           1       0.62      1.00      0.76      3528\n",
            "\n",
            "    accuracy                           0.62      5731\n",
            "   macro avg       0.31      0.50      0.38      5731\n",
            "weighted avg       0.38      0.62      0.47      5731\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zyVN8jfc_L1d",
        "v426lD42_YGX",
        "lKjBYFTb_m3E",
        "g7n4uNRHCPjf",
        "BZbw6iEUSMb7",
        "ozDQclUgR0iC",
        "2Ssm_sB2eaMP",
        "-WNxdLPNemhZ",
        "e3asxskTBe1O"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}